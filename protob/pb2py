#!/usr/bin/env python3
# Converts Google's protobuf python definitions of TREZOR wire messages
# to plain-python objects as used in TREZOR Core and python-trezor

import argparse
import importlib
import logging
import os
import subprocess
import sys
import tempfile
from collections import namedtuple

from google.protobuf import descriptor_pb2

ProtoField = namedtuple(
    "ProtoField", "name, number, proto_type, py_type, repeated, required, orig"
)

AUTO_HEADER = "# Automatically generated by pb2py\n"

# fmt: off
FIELD_TYPES = {
    descriptor_pb2.FieldDescriptorProto.TYPE_UINT64:  ('p.UVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_UINT32:  ('p.UVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_ENUM:    ('p.UVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_SINT32:  ('p.SVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_SINT64:  ('p.SVarintType', 'int'),
    descriptor_pb2.FieldDescriptorProto.TYPE_STRING:  ('p.UnicodeType', 'str'),
    descriptor_pb2.FieldDescriptorProto.TYPE_BOOL:    ('p.BoolType', 'bool'),
    descriptor_pb2.FieldDescriptorProto.TYPE_BYTES:   ('p.BytesType', 'bytes'),
}
# fmt: on


def remove_from_start(s, prefix):
    if s.startswith(prefix):
        return s[len(prefix) :]
    else:
        return s


def import_statement_from_path(path):
    # separate leading dots
    dot_prefix = ""
    while path.startswith("."):
        dot_prefix += "."
        path = path[1:]

    # split on remaining dots
    split_path = path.rsplit(".", maxsplit=1)
    leader, import_name = split_path[:-1], split_path[-1]

    if leader:
        from_part = dot_prefix + leader
    elif dot_prefix:
        from_part = dot_prefix
    else:
        from_part = ""

    if from_part:
        return "from {} import {}".format(from_part, import_name)
    else:
        return "import {}".format(import_name)


class Descriptor:
    def __init__(
        self,
        descriptor_file,
        message_type="MessageType",
        package=None,
        protobuf_module="protobuf",
    ):
        # parse descriptor
        self.descriptor = descriptor_pb2.FileDescriptorSet()
        with descriptor_file as f:
            self.descriptor.ParseFromString(f.read())

        # find relevant files (this omits `descriptor.proto` from trezor package)
        if package is None:
            self.files = self.descriptor.file
        else:
            self.files = [
                file for file in self.descriptor.file if file.package == package
            ]

        logging.debug(
            "found {} files (using package: {})".format(len(self.files), package)
        )

        # find messages and enums
        self.messages = []
        self.enums = []
        for file in self.files:
            self.messages += file.message_type
            self.enums += file.enum_type

        self.message_types = self.find_message_types(message_type)
        self.protobuf_import = import_statement_from_path(protobuf_module)

        self.out_dir = None
        self.module_index = None

    def find_message_types(self, message_type):
        message_types = {}
        try:
            message_type_enum = next(
                enum for enum in self.enums if enum.name == message_type
            )
            for value in message_type_enum.value:
                # strip leading "MessageType_"
                name = remove_from_start(value.name, "%s_" % message_type)
                message_types[name] = value.number

        except StopIteration:
            # No message type found. Oh well.
            logging.warning(
                "Message IDs not found under '{}'".format(args.message_type)
            )

        return message_types

    def parse_field(self, field):
        repeated = field.label == field.LABEL_REPEATED
        required = field.label == field.LABEL_REQUIRED
        if field.type == field.TYPE_MESSAGE:
            # ignore package path
            type_name = field.type_name.rsplit(".")[-1]
            proto_type = py_type = type_name
        else:
            try:
                proto_type, py_type = FIELD_TYPES[field.type]
            except KeyError:
                raise ValueError(
                    "Unknown field type %d for field %s" % (field.type, field.name)
                ) from None

        if repeated:
            py_type = "List[%s]" % py_type

        return ProtoField(
            name=field.name,
            number=field.number,
            proto_type=proto_type,
            py_type=py_type,
            repeated=repeated,
            required=required,
            orig=field,
        )

    def create_message_import(self, name):
        return "from .%s import %s" % (name, name)

    def process_message_imports(self, fields):
        imports = set(
            field.proto_type
            for field in fields
            if field.orig.type == field.orig.TYPE_MESSAGE
        )

        for name in sorted(imports):
            yield self.create_message_import(name)

    def create_init_method(self, fields):
        # please keep the yields aligned
        # fmt: off
        ... # https://github.com/ambv/black/issues/385
        yield         "    def __init__("
        yield         "        self,"
        for field in fields:
            yield     "        %s: %s = None," % (field.name, field.py_type)
        yield         "    ) -> None:"

        for field in fields:
            if field.repeated:
                yield "        self.{0} = {0} if {0} is not None else []".format(field.name)
            else:
                yield "        self.{0} = {0}".format(field.name)
        # fmt: on

    def process_message(self, message):
        logging.debug("Processing message %s", message.name)
        msg_id = self.message_types.get(message.name)

        # from .. import protobuf as p
        yield self.protobuf_import + " as p"

        fields = [self.parse_field(field) for field in message.field]

        if any(field.repeated for field in fields):
            yield "if __debug__:"
            yield "    try:"
            yield "        from typing import List"
            yield "    except ImportError:"
            yield "        List = None  # type: ignore"

        yield from self.process_message_imports(fields)

        yield ""
        yield ""
        yield "class %s(p.MessageType):" % message.name

        if msg_id is not None:
            yield "    MESSAGE_WIRE_TYPE = %d" % msg_id

        if fields:
            yield "    FIELDS = {"
            for field in fields:
                comments = []
                if field.required:
                    comments.append("required")
                if field.orig.HasField("default_value"):
                    comments.append("default=%s" % repr(field.orig.default_value))

                if comments:
                    comment = "  # %s" % " ".join(comments)
                else:
                    comment = ""

                if field.repeated:
                    flags = "p.FLAG_REPEATED"
                else:
                    flags = "0"

                yield "        %d: ('%s', %s, %s),%s" % (
                    field.number,
                    field.name,
                    field.proto_type,
                    flags,
                    comment,
                )

            yield "    }"
            yield ""
            yield from self.create_init_method(fields)

        if not fields and not msg_id:
            yield "    pass"

    def process_enum(self, enum):
        logging.debug("Processing enum %s", enum.name)

        for value in enum.value:
            # Remove type name from the beginning of the constant
            # For example "PinMatrixRequestType_Current" -> "Current"
            enum_prefix = enum.name
            name = value.name
            name = remove_from_start(name, "%s_" % enum_prefix)

            # If type ends with *Type, but constant use type name without *Type, remove it too :)
            # For example "ButtonRequestType & ButtonRequest_Other" => "Other"
            if enum_prefix.endswith("Type"):
                enum_prefix, _ = enum_prefix.rsplit("Type", 1)
                name = remove_from_start(name, "%s_" % enum_prefix)

            yield "%s = %s" % (name, value.number)

    def process_messages(self, messages):
        for message in sorted(messages, key=lambda m: m.name):
            self.write_to_file(message.name, self.process_message(message))
            self.write_to_index(self.create_message_import(message.name))

    def process_enums(self, enums):
        for enum in sorted(enums, key=lambda e: e.name):
            self.write_to_file(enum.name, self.process_enum(enum))
            self.write_to_index("from . import %s" % enum.name)

    def write_to_file(self, name, out):
        # Write generated sourcecode to given file
        logging.debug("Writing file %s.py" % name)
        with open(os.path.join(self.out_dir, "%s.py" % name), "w") as f:
            f.write(AUTO_HEADER)
            for line in out:
                f.write(line + "\n")

    def write_to_index(self, statement):
        if self.module_index:
            self.module_index.write(statement + "\n")

    def write_classes(self, out_dir, module_index=None):
        self.out_dir = out_dir
        self.module_index = module_index
        self.process_messages(self.messages)
        self.process_enums(self.enums)


if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)

    parser = argparse.ArgumentParser()
    # fmt: off
    parser.add_argument('proto', help="Protobuf definition file")
    parser.add_argument('out_dir', help="Directory for generated source code")
    parser.add_argument('-p', '--package', default="trezor", help="Name of protobuf package to extract. Use '-p all' to process all packages")
    parser.add_argument('-P', '--protobuf-module', default="protobuf", help="Name of protobuf module")
    parser.add_argument('-l', '--module-index', help="Generate list of modules")
    parser.add_argument('--message-type', default="MessageType", help="Name of enum with message IDs")
    parser.add_argument("--protobuf-default-include", default="/usr/include", help="Location of protobuf's default .proto files.")
    # fmt: on
    args = parser.parse_args()

    if not os.path.exists(args.proto):
        print("Proto file does not exist: %s" % args.proto)
        sys.exit(1)

    with tempfile.TemporaryDirectory() as tmpdir:
        logging.debug("Compiling proto definition from %s", args.proto)
        proto_dir = os.path.dirname(args.proto)
        descriptor_set_filename = os.path.join(tmpdir, "DESCRIPTOR_SET")
        protoc_includes = [
            "-I%s" % dir for dir in [args.protobuf_default_include, proto_dir]
        ]
        subprocess.check_call(
            [
                "protoc",
                "--descriptor_set_out=" + descriptor_set_filename,
                "--include_imports",
                args.proto,
            ]
            + protoc_includes
        )

        with open(descriptor_set_filename, "rb") as f:
            descriptor = Descriptor(
                f,
                message_type=args.message_type,
                package=args.package if args.package != "all" else None,
                protobuf_module=args.protobuf_module,
            )

    with tempfile.TemporaryDirectory() as tmpdir:
        module_index_name = os.path.join(tmpdir, "__module_index.py")
        with open(module_index_name, "w") as module_index:
            descriptor.write_classes(tmpdir, module_index)

        if args.module_index:
            os.replace(module_index_name, args.module_index)
        else:
            os.unlink(module_index_name)

        for filename in os.listdir(args.out_dir):
            pathname = os.path.join(args.out_dir, filename)
            try:
                with open(pathname, "r") as f:
                    if next(f, None) == AUTO_HEADER:
                        os.unlink(pathname)
            except Exception:
                pass

        for filename in os.listdir(tmpdir):
            src = os.path.join(tmpdir, filename)
            dst = os.path.join(args.out_dir, filename)
            os.replace(src, dst)
